\chapter{基于非一致可靠性存储的数据可用性评估策略}
\section{引言}
在分布式存储系统中，由于数据的类型和用途等存在差异，因此重要性往往不尽相同。在对象存储系统中，我们可以定义对象持久性 $p_{f}'$，对于至关重要的数据，选取相对更高的对象持久性，对象数据发生损坏的概率更小，数据更加安全，但此时需要相应的冗余备份数增加，存储成本更高。相反，对于重要性一般的数据，选取适中的对象持久性，可以更加有效地利用存储资源，减少冗余数据。

同时，在存储系统中的数据可靠性通常受多种因素影响。首先，对于不同类型的存储设备，比如机械硬盘和固态硬盘，介质的存储机理不同，因此寿命通常是不同的。对于相同存储设备，不同批次间制造水平的差异以及制造过程中的误差也会导致存储介质寿命的差异性。对于同一介质，随着使用时间的不断增长，发生故障的可能性也会不断变化，存储于其中的数据的可靠性也会随之改变。在本章中，我们提出了一种基于存储设备实时状态对设备中数据可用性进行推断的算法，从而动态地估计数据损坏发生的可能性，为数据备份策略提供指导。

因此，我们提出了一种基于数据可用性和存储设备可靠性的动态要求，进行自适应纠删码编码的策略 On-demand ARECS。在纠删码存储系统中，对于从分布式存储系统中任意选出的 $n+m$ 块硬盘，将待存储的对象数据分为 $n$ 份，同时增加 $m$ 份纠删码校验数据，分别存储于这 $n+m$ 块磁盘上。我们需要根据每块磁盘 $d_j$ 的型号和使用时间等要素推断出其当前发生故障的概率 $p_{d_j}$，从而计算得到在这 $n+m$ 块磁盘上存储的数据的正确率 $p_{f}(n,m)$。在此基础上，我们只需选择满足约束 $p_{f}(n,m) \geq p_{f}'$ 的纠删码存储方案，即可保障数据存储是安全且高效的。

此外，在实际的分布式数据中心中，通常均有专人负责损坏硬盘的更换和数据重建，因此硬盘更换和重建所需的时间也应是系统中一个重要的变量。我们假设硬盘更换和重建时间为 $t_r$ 年，在 $t_r$ 周期内计算对象的持久性需求 $p_{f}'$ 和数据的正确率 $p_{f}(n,m)$ 间的关系，并对模型进行完善。
\section{不同类型数据的可用性}
\subsection{数据重要性与数据可用性的关系}
对于不同类型的数据，重要性通常并不相同\cite{andronikou2012dynamic}。对于重要性强、数据丢失后果严重的数据，如银行账户数据、业务合同数据、客户账号数据等，我们会通过增加备份数量、改进备份策略、异地备份和离线备份等多种方式尽可能地确保数据安全。而对于重要性一般、数据丢失影响较小的数据，如应用运行日志、下载的电影等，我们通过存储更少的备份数据，节约存储资源，实现对数据的分级处理。
\subsection{对象存储系统中的数据可用性指标}
在对象存储系统中，数据的可用性可以使用对象持久性指标来衡量，对象的持久性数值取决于数据的重要程度。在目前各大公有云的分布式存储服务中，其服务等级协议（Service Level Agreement，即 SLA）内均承诺了一年期对象持久性，具体数值如表 \ref{t1} 所示。

在亚马逊云的对象存储服务中，保证的一年期对象持久性为 $p_{f}'=99.999999999\%$，也就是说，数据在一年之内出现错误的概率小于 $10^{-11}$。在微软的 Azure 对象存储服务\cite{huang2012erasure}中，保证的一年期对象持久性与选取的备份方法有关。对于本地备份（Locally-Redundant Storage，即 LRS）来说，微软保证一年内错误率小于 $10^{-11}$，对于跨可用区备份（Zone-Redundant Storage，即 ZRS）来说此数值为 $10^{-12}$，对于异地备份（Geo-Redundant Storage，即 GRS）来说此数值为 $10^{-16}$。

\begin{table}[!htb]
\centering
\caption{云存储服务提供商保证的对象持久性}
\begin{tabular}{c|c}
\hline
存储服务提供商 & 对象持久性\\\hline
Amazon S3\cite{amazon2020amazon} & 99.999999999\%\\\hline
Azure Blob Storage (LRS)\cite{microsoft2020azure} & 99.999999999\%\\\hline
Azure Blob Storage (ZRS)\cite{microsoft2020azure} & 99.9999999999\%\\\hline
Azure Blob Storage (GRS)\cite{microsoft2020azure} & 99.99999999999999\%\\\hline
\end{tabular}
\label{t1}
\end{table}
\subsection{提高数据可用性的成本收益分析}
对于重要的数据，我们需要保证更高的数据可用性，因此需要选择更高的对象持久性保证的存储系统。也就是说，数据的重要性与 $p_{f}'$ 的选取是正相关的。但是，要想提高 $p_{f}'$，就需要更多的存储设备来存储数据的冗余备份，存储系统的成本也会随之上升。我们对数据存储过程的成本和收益进行分析可以发现，若假设一个单位的数据价值为 $x$ 个单位，则可用性为 $p_{f}'$ 时数据的收益为 $xp_{f}'$。假设存储系统的对象持久性达到 $p_{f}'$ 时，每个单位数据需要占用 $s(p_{f}')$ 单位的存储节点，每个单位的存储节点价格为 $y$ 个单位，则数据存储的成本为 $ys(p_{f}')$。因此可以得到系统在存储收益和存储成本相等时的平衡点为：
$$
xp_{f}'=ys(p_{f}')
$$

在达到此平衡点后，若继续提高数据可用性，数据存储的边际成本会大于其边际收益，造成存储资源的浪费。因此，我们需要根据不同类型数据的重要程度，有针对性地选取对象持久性 $p_{f}'$，进而提升存储系统的成本收益率。
\section{数据可用性和磁盘故障率的关系}
\subsection{固定磁盘故障率模型}
在目前的分布式存储系统中，一般均采用固定的存储设备故障率的模型，来计算对象的持久性。固定磁盘故障率模型假设系统中共有 $n+m$ 块磁盘，每块硬盘故障率为 $p_d$，易得硬盘完好的概率为 $1-p_d$。假设硬盘发生损坏是独立随机事件，也就是不同硬盘的损坏之间没有关联，那么根据概率计算的乘法公式，可以推导得出，在 $n+m$ 块磁盘中，恰好有 $i$ 块磁盘发生故障，另 $n+m-i$ 块磁盘完好的概率为：
$$
\dbinom{n+m}{i}p_{d}^{i}(1-p_d)^{n+m-i}
$$

其中 $\dbinom{n+m}{i}$ 为二项式系数，代表着从 $n$ 块硬盘中任选 $i$ 块硬盘的所有组合数。

对于有 $n$ 个数据块，$m$ 个校验块的纠删码编码，要想保障对象的持久性，需要至少有 $m$ 块硬盘不发生故障，因此概率为恰好有 $0$ 块磁盘故障到恰好有 $m$ 块磁盘故障的所有可能性求和。即：
$$
p_{f}(n,m)=\sum_{i=0}^{m}{\dbinom{n+m}{i}p_{d}^{i}(1-p_d)^{n+m-i}}
$$

其中 $p_f$ 即为对象的持久性，满足 $0<p_f<1$，数据块 $n$ 和校验块 $m$ 满足 $n>0$ 且 $m>0$，硬盘故障率 $p_d$ 满足 $0<p_d<1$。

特别地，若取 $n=1$，那么系统便退化为多副本备份，此时对象持久性为：
$$
p_{f}(1,m)=\sum_{i=0}^{m}{\dbinom{1+m}{i}p_{d}^{i}(1-p_d)^{1+m-i}}
$$

根据二项式定理：
$$
(x+y)^n=\sum_{i=0}^{n}{\dbinom{n}{i}x^{i}y^{n-i}}
$$

我们有：
$$
\left(p_d+(1-p_d)\right)^{1+m}=\sum_{i=0}^{1+m}{\dbinom{1+m}{i}p_{d}^{i}(1-p_d)^{1+m-i}}
$$

代入多副本备份的对象持久性公式中，得：
\begin{align*}
p_{f}(1,m)&=\sum_{i=0}^{m}{\dbinom{1+m}{i}p_{d}^{i}(1-p_d)^{1+m-i}}\\
&=\left(\sum_{i=0}^{1+m}{\dbinom{1+m}{i}p_{d}^{i}(1-p_d)^{1+m-i}}\right)\\
&\quad-\left(\dbinom{1+m}{1+m}p_{d}^{1+m}(1-p_d)^{1+m-(1+m)}\right)\\
&=\left(p_d+(1-p_d)\right)^{1+m}-p_{d}^{1+m}(1-p_d)^{0}\\
&=1^{1+m}-p_{d}^{1+m}\\
&=1-p_{d}^{1+m}
\end{align*}

此公式即退化为在多副本备份中，要想保证数据不丢失，需要满足所有硬盘不同时损坏。对象的持久性为 $1$ 减去所有磁盘同时发生损坏的概率。
\subsection{动态磁盘故障率模型}
但在实际情况中，每块磁盘型号和磁盘使用时间经常不尽相同，导致磁盘故障率也存在差异。因此，我们可以尝试根据磁盘的统计信息，预测得到不同磁盘当前的故障率。根据预测得到的差异化故障率，我们可以据此计算对象持久性，从而更大限度的降低纠删码编码的存储冗余。
\subsubsection{基于磁盘统计信息的磁盘故障率预测}
根据 Ma 等\cite{ma2015raidshield}的研究，由于磁盘在扇区损坏时会重新分配完好的扇区来进行代替，因此磁盘的重分配的扇区数（Reallocated Sectors）与磁盘的故障率密切相关，其中磁盘的重分配扇区数可以通过其 S.M.A.R.T. 信息\cite{allen2004monitoring}获得。磁盘的故障率可以根据 S.M.A.R.T. 等信息来预测\cite{xu2018improving,mahdisoltani2017proactive,lu2020making,dos2017predicting,chaves2018hard,botezatu2016predicting,anantharaman2018large}。根据贝叶斯定理（Bayes' Theorem），我们可以使用数据中心完好磁盘和损坏磁盘的统计信息，预测磁盘故障率。

贝叶斯定理是概率论中的一个定理，描述在已知一些条件下某事件的发生概率。关于随机事件 $A$ 和 $B$ 的条件概率，贝叶斯定理给出了：
$$
P(A|B)=\dfrac{P(B|A)P(A)}{P(B)}
$$

其中：
\begin{itemize}
\item $P(A|B)$ 是已知 $B$ 发生后，$A$ 的条件概率。也由于得自 $B$ 的取值而被称作 $A$ 的后验概率
\item $P(A)$ 是 $A$ 的先验概率（或边缘概率）。之所以称为“先验”是因为它不考虑任何 $B$ 方面的因素
\item $P(B|A)$ 是已知 $A$ 发生后，$B$ 的条件概率。也由于得自 $A$ 的取值而被称作 $B$ 的后验概率
\item $P(B)$ 是 $B$ 的先验概率
\end{itemize}

在数据中心的所有完好磁盘和损坏磁盘中，我们定义：
\begin{itemize}
\item $N_{RS}$ 是一块磁盘的重分配扇区数
\item $P(fail|N_{RS})$ 重分配扇区数至少为 $N_{RS}$ 的磁盘故障率
\item $P(fail)$ 是磁盘发生故障的概率
\item $P(N_{RS}|fail)$ 是一块故障磁盘重分配扇区数大于 $N_{RS}$ 的概率
\item $P(N_{RS})$ 是磁盘重分配扇区数大于 $N_{RS}$ 的概率
\end{itemize}

根据贝叶斯定理，我们可以得到这块硬盘的故障率：
\begin{align*}
p_d&=P(fail|N_{RS})\\
&=\dfrac{P(N_{RS}|fail){\times}P(fail)}{P(N_{RS})}\\
&=\dfrac{\dfrac{\mathrm{num.\ of\ failed\ disks\ with\ }N_{RS}}{\mathrm{num.\ of\ failed\ disks}}\times\dfrac{\mathrm{num.\ of\ failed\ disks}}{\mathrm{num.\ of\ disks}}}{\dfrac{\mathrm{num.\ of\ all\ disks\ with\ }N_{RS}}{\mathrm{num.\ of\ disks}}}\\
&=\dfrac{\mathrm{num.\ of\ failed\ disks\ with\ }N_{RS}}{\mathrm{num.\ of\ all\ disks\ with\ }N_{RS}}
\end{align*}

因此，我们可以根据数据中心中所有完好磁盘和损坏磁盘的 $N_{RS}$ 统计量，预测磁盘的故障率 $p_d$。
\subsubsection{基于动态磁盘故障率的对象可用性计算}
为了定量地描述动态磁盘故障率模型，我们首先需要对磁盘组的几种数学表达进行定义。首先我们定义 $n$ 块硬盘 $\{d_1,d_2,\cdots,d_n\}$，对于由 $n$ 块硬盘组成的集合则为 $S_{d}'(n)=\{d_1,d_2,\cdots,d_n\}$，其中 $\|S_{d}'(n)\|=n$。其次定义集合 $S_{a}(n,k)$ 为 ${\forall}S_{d}{\in}S_{a}(n,k)$ 均满足下述性质的集合：
\begin{itemize}
\item ${\forall}d_{i}{\in}S_{d}$ 均有 $d_{i}{\in}S_{d}'(n)$
\item $\|S_{d}\|=k$
\item $\|S_{a}(n,k)\|=\dbinom{n}{k}$
\end{itemize}

也就是说，$S_{a}(n,k)$ 为从 $S_{d}'(n)$ 中任取 $k$ 个元素组成的集合的全体，即：
$$
S_{a}(n,k)=\left\{\{d_{1},d_{2},\cdots,d_{k}\},\{d_{1},\cdots,d_{k-1},d_{k+1}\},\cdots,\{d_{n-k+1},d_{n-k+2},\cdots,d_{n}\}\right\}
$$

基于上述定义，我们对动态磁盘故障率模型的对象持久性进行计算。易知，对于任意磁盘集合 $S_{d}{\subseteq}S_{d}'(n)$，其相对于全集 $S_{d}'(n)$ 的补集为 $S_{d}'(n)-S_{d}$。假设存在一块磁盘 $d_j$，该磁盘的故障率为 $p_{d_j}$，若对于磁盘损坏事件来说满足独立事件假设，即不同磁盘的损坏之间没有内在联系，那么根据概率论的乘法公式，可以得到 $S_{d}$ 全部损坏，并且 $S_{d}'(n)-S_{d}$ 全部完好的概率为：
$$
\left(\prod_{{\forall}d_{j}{\in}S_{d}}{p_{d_j}}\right)\left(\prod_{{\forall}d_{j}{\in}S_{d}'(n+m)-S_{d}}(1-p_{d_j})\right)
$$

根据纠删码的解码原理，我们需要至少 $n$ 块磁盘是完好的，或者说至多有 $m$ 块磁盘是损坏的。因此，只要在存储数据块和编码块的全部磁盘 $S_{d}'(n+m)$ 中存在磁盘组 $S_{good}$，满足 $S_{good}$ 中的所有磁盘均是可用的，$S_{good}{\subseteq}S_{d}'(n)$ 且 $\|S_{good}\| \geq n$，我们便可根据 $S_{good}$ 磁盘组中的数据恢复出全部的原始数据。由此，我们可以得到 $S_{good}$ 的取值范围 ${\forall}S_{good}{\in}S_{a}(n+m,i)$，其中 $0 \leq i \leq m$。

由于满足对象持久性约束的情况为满足上述条件的全体，根据概率论的加法公式，求和得到概率为：
$$
p_{f}(n,m)=\sum_{i=0}^{m}\sum_{{\forall}S_{d}{\in}S_{a}(n+m,i)}\left[\left(\prod_{{\forall}d_{j}{\in}S_{d}}{p_{d_j}}\right)\left(\prod_{{\forall}d_{j}{\in}S_{d}'(n+m)-S_{d}}(1-p_{d_j})\right)\right]
$$

特别地，当公式中的 $p_{d_j}$ 均取值 $p_d$ 时，也就是各磁盘故障率相同，此公式便退化为固定磁盘故障率的对象持久性公式：
\begin{align*}
p_{f}(n,m)&=\sum_{i=0}^{m}\sum_{{\forall}S_{d}{\in}S_{a}(n+m,i)}\left[\left(\prod_{{\forall}d_{j}{\in}S_{d}}{p_d}\right)\left(\prod_{{\forall}d_{j}{\in}S_{d}'(n+m)-S_{d}}(1-p_d)\right)\right]\\
&=\sum_{i=0}^{m}\sum_{{\forall}S_{d}{\in}S_{a}(n+m,i)}\left[\left({p_d}^{\|S_{d}\|}\right)\left((1-p_d)^{\|S_{d}'(n+m)-S_{d}\|}\right)\right]\\
&=\sum_{i=0}^{m}\sum_{{\forall}S_{d}{\in}S_{a}(n+m,i)}\left[\left({p_d}^{i}\right)\left((1-p_d)^{n+m-i}\right)\right]\\
&=\sum_{i=0}^{m}\|S_{a}(n+m,i)\|\left({p_d}^{i}(1-p_d)^{n+m-i}\right)\\
&=\sum_{i=0}^{m}\dbinom{n+m}{i}{p_d}^{i}(1-p_d)^{n+m-i}
\end{align*}
\section{损坏节点更换对模型的影响}
在上述分析中，对于总节点数为 $s$ 的存储系统，若待存储对象持久性为 $p_{f}'$，On-demand ARECS 算法需要在所有的节点中选取 $n+m$ 个节点，满足 $p_{f}(n,m) \geq p_{f}'$，从而做到在保证对象的持久性需求的基础上，选取最优的编码策略。然而，上述分析中的对象持久性和磁盘故障率均按照一年期进行计算，但在实际的数据中心中，存储系统的运行和维护人员每个工作日均会对节点状态进行检查，并对损坏节点进行替换与数据的恢复重建。我们假设一个节点从损坏到被发现且替换并重建数据的时间为 $t_{r}$ 年，显然 $t_{r}{\ll}1$，我们用在 $t_{r}$ 周期内的对象持久性和磁盘故障率对上述公式进行替换：
$$
p_{f}(n,m)=\sum_{i=0}^{m}\sum_{{\forall}S_{d}{\in}S_{a}(n+m,i)}\left[\left(\prod_{{\forall}d_{j}{\in}S_{d}}{p_{d_j}'}\right)\left(\prod_{{\forall}d_{j}{\in}S_{d}'(n+m)-S_{d}}(1-p_{d_j}')\right)\right]
$$

其中的 $p_{f}'$ 和 $p_{d}'$ 的取值为在 $t_{r}$ 周期内的损坏概率，而非一年期的概率值。假设在一年内各个时点磁盘损坏的可能性相同且独立，则可以得到 $p_{d}'=1-(1-p_{d})^{t_{r}}$，$p_{f}'=p_{f}^{t_{r}}$。因此对于 On-demand ARECS 算法来说，需要选取的编码策略 $(n+m,n)$ 应该满足计算的节点可靠性大于等于对象的持久性。在 $t_{r}$ 周期内，模型确定的节点可靠性和对象持久性的差值为：
\begin{align*}
f(n,m)=\sum_{i=0}^{m}\sum_{{\forall}S_{d}{\in}S_{a}(n+m,i)}&\left[\left(\prod_{{\forall}d_{j}{\in}S_{d}}\left(1-(1-p_{d_j})^{t_r}\right)\right)\right.\\
&\cdot\left.\left(\prod_{{\forall}d_{j}{\in}S_{d}'(n+m)-S_{d}}(1-p_{d_j})^{t_{r}}\right)\right]-p_{f}^{t_{r}}
\end{align*}

显然节点可靠性应达到或超过对象的持久性意味着此差值为非负值，即 $f(n,m) \geq 0$。由于编码的检验块数量 $m$ 越少，数据冗余度越低，存储延迟越小，因此 $m$ 应取满足约束 $f(n,m) \geq 0$ 的最小值：
$$
m(n)=\operatorname*{argmin}_{m}f(n,m),\ \operatorname*{where}\ f(n,m) \geq 0
$$
\section{实验与分析}
\subsection{模拟实验环境}
在这一节的内容中，我们将通过模拟实验的方法，设计一个分布式存储系统实验环境，用以模拟并分析成本收益模型下的对象可用性选取，以及 On-demand ARECS 磁盘故障率模型的磁盘冗余度。根据 Pinheiro 等人的研究\cite{pinheiro2007failure}，使用时间为一年的磁盘 $p_{d}=1.7\%$，而使用时间为三年的磁盘 $p_{d}=8.6\%$。我们选取一个模拟实验环境，模拟实现了两种存储节点，节点 $A$ 的磁盘故障率为 $p_{d_{A}}=1.7\%$，节点 $B$ 的磁盘故障率为 $p_{d_{B}}=8.6\%$，存储系统中分别有 $18$ 个节点 $A$ 和节点 $B$。在通常的数据中心中，由于有专门人员负责损坏节点的检测与更换，因此损坏节点基本均能被及时发现。对于损坏节点的数据重建，因为目前的硬盘存取速度已经较快，因此正常情况下的用时也不会太长。基于此，我们不妨选取更换损坏硬盘并重建数据为 $3$ 天，即取 $t_{r}=\dfrac{3}{365}$。基于此实验环境，我们进行了以下模拟与分析。
\subsection{不同磁盘故障率模型与磁盘冗余度模拟与分析}
我们首先模拟在不同的磁盘故障率模型下，不同编码方案对应的数据冗余度。根据前文的分析，目前各主要云存储服务提供商对于对象持久性的保证值一般均为 $p_{f}=99.999999999\%$，我们在此实验中不妨也选取此值作为数据的可用性需求。对于数据冗余度来说，其定义为冗余数据量和原始数据量的比值，可记为 $\dfrac{m}{n}$。我们通过模拟实验可以得出，On-demand ARECS 的动态磁盘可靠性模型与传统的固定磁盘可靠性模型的数据冗余度对比如图 \ref{p5}。

\begin{figure}[!htb]
\centering
\resizebox{.8\textwidth}{!}{\input{figures/figure5}}
\caption{不同硬盘故障率模型的数据切分数与冗余度关系}
\label{p5}
\end{figure}

从图 \ref{p5} 中我们可以看出，虽然在总体上 On-demand ARECS 动态磁盘故障率模型的磁盘冗余度相比固定磁盘故障率模型低，但是在一些特殊情况下，比如 $n=21$ 到 $n=24$ 时，On-demand ARECS 动态磁盘故障率模型和固定磁盘故障率模型得到了相同的结果，即均选取了 $m=5$ 的编码方案。我们分析实验过程可以发现，如果单纯对于概率的计算来说，只要 $n$ 值和 $m$ 值选取相同，则数据冗余度就是相同的。而在实际的分布式存储系统中，我们需要对编码块的数量，即 $m$ 的值进行向上取整，对于我们的实验环境来说，我们根据公式：
$$
m(n)=\operatorname*{argmin}_{m}f(n,m),\ \operatorname*{where}\ f(n,m) \geq 0
$$
计算 $n=21$ 到 $n=24$ 时得到的 $m$ 值均满足 $4<m<5$，那么我们就需要选取 $m=5$ 才能保障数据安全。换句话说，不管实际上我们需要 $4.1$ 个校验块，还是实际上需要 $4.9$ 个校验块，我们都需要向上取整为 $5$ 个校验块。因此，$m$ 值的选取为了具有实际意义，其公式应为：
$$
m(n)=\left\lceil\operatorname*{argmin}_{m}f(n,m)\right\rceil,\ \operatorname*{where}\ f(n,m) \geq 0
$$

由于 On-demand ARECS 算法核心在于对于不同的节点状况动态选取合适的 $n$ 值，也就是说，我们无法预先确定一个 $n$ 值，然后计算其最优的存储方案，我们需要在算法中动态选择负载低、带宽高的节点，因而 $n$ 值的最终确定需要在实际系统中动态确定。故在 On-demand ARECS 的动态磁盘故障率模型中，我们主要需要关注平均性能，也就是说对于所有 $n$ 值来说，平均冗余度更低。

通过图 \ref{p5} 的实验结果中我们可以看出，On-demand ARECS 模型相比于传统算法，将数据冗余度平均降低了 $18\%$，而最坏性能与传统固定磁盘故障率模型相当。
\subsection{数据可用性与成本收益模拟与分析}
根据 Liu 等人的研究\cite{liu2018implementation}和 Tahoe 分布式文件系统\cite{wilcox2008tahoe}的默认实现，我们可以发现 $n$ 一般均选取 $n=10$ 左右较为合适。因此在我们本节的模拟中，我们不妨选取 $n=10$ 来进行分析。对于具体 $n$ 值的选取，我们将在下一章中通过对存储系统当前状态的分析，动态选取确定最优的编码方案和节点。

根据前文的分析，数据可用性的取值主要受制于数据本身的重要性，其简化的成本收益模型为：
$$
xp_{f}'=ys(p_{f}')
$$

其中等式左半部分为存储系统的边际收益，右半部分为存储系统的边际成本。我们假设一份数据存储的成本为 $80$ 个单位，数据本身的价值为 $100$ 个单位，那么我们可以得到在不同磁盘故障率模型下，边际成本与边际收益的曲线图如图 \ref{p14} 所示。

\begin{figure}[!htb]
\centering
\resizebox{.8\textwidth}{!}{\input{figures/figure14}}
\caption{不同硬盘故障率模型的边际成本与边际收益分析}
\label{p14}
\end{figure}

从图 \ref{p14} 中可以看出，存储数据的边际成本相比于存储数据的边际收益上升更快，在固定磁盘故障率模型下，针对上述模拟实验环境，$p_{f}'\approx99.995\%$ 时边际成本和边际收益相等。在 On-demand ARECS 浮动磁盘故障率模型下，针对上述模拟实验环境，$p_{f}'\approx99.999995\%$ 时边际成本和边际收益相等。

综上所述，On-demand ARECS 浮动磁盘故障率模型相比于固定磁盘故障率模型，达到边际成本收益平衡点时，对象持久性提高了三个数量级。在达到此平衡点后，若盲目增大对象的持久性 $p_{f}'$ 对于存储系统来说是得不偿失的。
\section{小结}
在本章中，我们首先介绍了数据可用性的概念，说明了选取适当的数据可用性的意义。其次，我们针对存储系统中磁盘的特点，给出了一种推测磁盘可靠性的方法，并基于此计算对象的持久性。我们提出了 On-demand ARECS 动态磁盘故障率模型取代传统的固定磁盘故障率模型，以对实时推测的变化故障率的磁盘进行对象可靠性的计算。我们还分析了在数据中心中，定期维护、更换损坏磁盘和重建数据对对象可用性的影响。我们通过模拟实验的方式，对比分析了固定磁盘可靠性模型和 On-demand ARECS 动态磁盘可靠性模型。在模拟环境中，在达到预期对象可用性的条件下，On-demand ARECS 动态磁盘可靠性模型相比固定磁盘可靠性模型，将磁盘冗余度平均降低了 $18\%$。在达到边际成本收益平衡点的条件下，On-demand ARECS 动态磁盘可靠性模型相比固定磁盘可靠性模型，将对象可用性提高了三个数量级。
